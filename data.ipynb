{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import escape\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"~/Downloads/data/companies_sorted.csv\"\n",
    "\n",
    "# Number of random rows to select\n",
    "n_rows = 1000\n",
    "\n",
    "# Output text file path\n",
    "output_file_path = \"data/companies.txt\"\n",
    "\n",
    "# Step 1: Load CSV as a Dask DataFrame\n",
    "df = dd.read_csv(csv_file_path, assume_missing=True)\n",
    "\n",
    "# Step 2: Get a sample of 100,000 rows (sampling happens at random)\n",
    "sampled_df = df.sample(frac=n_rows / len(df), replace=False).compute()\n",
    "\n",
    "# Step 3: Extract the second column (adjust index if needed)\n",
    "companies = sampled_df.iloc[:, 1]  # Adjust index if needed based on your CSV structure\n",
    "\n",
    "# Step 4: Remove outer quotes from the values\n",
    "companies = companies.str.replace('\"', '')\n",
    "\n",
    "# Step 5: Write to a plain text file, one value per line\n",
    "companies.to_csv(output_file_path, index=False, header=False, quoting=3, escapechar='\\\\', sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random domains from a CSV file\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"~/Downloads/data/domains.csv\"\n",
    "\n",
    "# Number of random rows to select\n",
    "n_rows = 1000\n",
    "\n",
    "# Output text file path\n",
    "output_file_path = \"data/domains.txt\"\n",
    "\n",
    "# Step 1: Load CSV as a Dask DataFrame\n",
    "df = dd.read_csv(csv_file_path, assume_missing=True, sep=';')\n",
    "\n",
    "# Step 2: Get a sample of 100,000 rows (sampling happens at random)\n",
    "sampled_df = df.sample(frac=n_rows / len(df), replace=False).compute()\n",
    "\n",
    "# Step 3: Extract the first column (adjust index if needed)\n",
    "domains = sampled_df.iloc[:, 0]  # Adjust index if needed based on your CSV structure\n",
    "\n",
    "# Step 4: Remove outer quotes from the values\n",
    "domains = domains.str.replace('\"', '')\n",
    "\n",
    "# Step 5: Write to a plain text file, one value per line\n",
    "domains.to_csv(output_file_path, index=False, header=False, quoting=3, escapechar='\\\\', sep='|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate IP addresses\n",
    "\n",
    "from ner.ipgen import generate_ipv4_addresses, generate_ipv6_addresses\n",
    "\n",
    "with open(\"data/ipv4_addresses.txt\", \"w\") as f:\n",
    "    for ip in generate_ipv4_addresses(1000):\n",
    "        f.write(ip + \"\\n\")\n",
    "\n",
    "with open(\"data/ipv6_addresses.txt\", \"w\") as f:\n",
    "    for ip in generate_ipv6_addresses(1000):\n",
    "        f.write(ip + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate URLs\n",
    "\n",
    "from ner.urlgen import generate_urls\n",
    "\n",
    "with open(\"data/urls.txt\", \"w\") as f:\n",
    "    for url in generate_urls(1000):\n",
    "        f.write(url + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "# Reinitialize Faker instance after environment reset\n",
    "faker = Faker()\n",
    "\n",
    "# Generate 1000 unique email addresses using Faker\n",
    "unique_emails = set()\n",
    "while len(unique_emails) < 1000:\n",
    "    unique_emails.add(faker.email(safe=False))\n",
    "\n",
    "# Write to file\n",
    "with open(\"data/emails.txt\", \"w\") as f:\n",
    "    for email in unique_emails:\n",
    "        f.write(email + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.datagen import generate_ner_dataset\n",
    "\n",
    "generate_ner_dataset(\"data/ner_dataset.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-zCheM3vK-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
